{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D48rgmQSB0B6"
   },
   "source": [
    "# Laboratoria 9: BERT i atencja\n",
    "\n",
    "\n",
    "### Zadanie 1 (3 pkt), atencja dekodera względem (en)kodera\n",
    "\n",
    "Poniżej znajdują się dwie macierze, `encoder_states` oraz `decoder_states` reprezentujące stan warstwy ukrytej po przetworzeniu każdego slowa z enkodera i dekodera. Pojedynczy stan warstwy ukrytej zawiera embedding o dlugosci = 3. W enkoderze mamy 4 stany warstwy ukrytej RNNów, gdyż przetwarzamy sekwencję 4 tokenów.\n",
    "\n",
    "W dekoderze mamy 5 tokenów, które powinny być wygenerowane z sekwencji przetwarzanej (en)koderem.\n",
    "\n",
    "Zadanie polega na:\n",
    "a) Obliczniu podobieństwa wszystkich embeddingów z dekodera (queries) względem wszystkich embeddingów kolejnych stanów (en)kodera (keys) [pamiętajcie, że macierze potrafią w transponowanie. W `NumPy` macierz transponujemy za pomocą `macierz.T`]\n",
    "\n",
    "b) Na utworzonej macierzy podobieństwa należy wykonać softmax (zaimportowany z scipy). Uwaga:  pamiętajcie, żeby aplikować softmax w dobrym wymiarze. Wszystkie stany ukryte enkodera powinny zostac zasoftmaksowane względem zadanego stanu dekodera, nie odwrotnie. W scipy, funkcja softmax zawiera argument axis, który może pomóc.\n",
    "\n",
    "c) Należy wykorzystać macierz atencji z kroku b) i `encoder_states` do wygenerowania macierzy zawierającej wektory kontekstu dla każdego tokenu z dekodera.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "vQsum9iYATge"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  4.806   2.376   7.762   1.129]\n",
      " [ 12.164 -12.645  73.935   3.636]\n",
      " [ 27.79  -16.962  94.002   7.137]\n",
      " [ 18.702  -5.184  42.616   4.501]\n",
      " [ 64.38   49.86   56.21   14.45 ]]\n",
      "[[4.91780633e-02 4.32948093e-03 9.45248312e-01 1.24414389e-03]\n",
      " [1.49003187e-27 2.50486173e-38 1.00000000e+00 2.94803216e-31]\n",
      " [1.75587568e-29 6.44090821e-49 1.00000000e+00 1.88369172e-38]\n",
      " [4.11416552e-11 1.74069934e-21 1.00000000e+00 2.79811669e-17]\n",
      " [9.99716568e-01 4.94220792e-07 2.82937800e-04 2.06801368e-22]]\n",
      "[[ 9.69108631  0.35799187  0.59163688]\n",
      " [10.2         0.2         0.3       ]\n",
      " [10.2         0.2         0.3       ]\n",
      " [10.2         0.2         0.3       ]\n",
      " [ 1.20254471  3.39909302  5.59850122]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import *\n",
    "from scipy.special import softmax\n",
    "\n",
    "encoder_states = array(\n",
    "  # Embedding z warstwy ukrytej enkodera w kroku 1, np. dla slowa Ala\n",
    "  [[1.2, 3.4, 5.6],\n",
    "   # Embedding z warstwy ukrytej enkodera w kroku 2, np. dla slowa ma\n",
    "   [-2.3, 0.2, 7.2],\n",
    "   # Embedding z warstwy ukrytej enkodera w kroku 3, np. dla slowa kota\n",
    "   [10.2, 0.2, 0.3],\n",
    "   # Embedding z warstwy ukrytej enkodera w kroku 4, np. dla token'u <EOS> (koniec sekwencji)\n",
    "   [0.4, 0.7, 1.2]]\n",
    ")\n",
    "\n",
    "decoder_states = array(\n",
    "  # Embedding z warstwy ukrytej dekodera w kroku 1, np. przed wygenerowaniem slowa Alice\n",
    "  [[0.74, 0.23, 0.56],\n",
    "   # Embedding z warstwy ukrytej dekodera w kroku 2, np. przed wygenerowaniem slowa owns\n",
    "   [7.23, 0.12, 0.55],\n",
    "   # Embedding z warstwy ukrytej dekodera w kroku 3, np. przed wygenerowaniem slowa a\n",
    "   [9.12, 4.23, 0.44],\n",
    "   # Embedding z warstwy ukrytej dekodera w kroku 4, np. przed wygenerowaniem slowa cat\n",
    "   [4.1, 3.23, 0.5],\n",
    "   # Embedding z warstwy ukrytej dekodera w kroku 5, np. przed wygenerowaniem slowa cat\n",
    "   [5.2, 3.1, 8.5]]\n",
    ")\n",
    "print(\n",
    "  probabilities := (encoder_states @ decoder_states.T).T,\n",
    "  softmax_ := softmax(probabilities, axis=1),\n",
    "  context := softmax_ @ encoder_states,\n",
    "  sep='\\n'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lwhDwdaTnPku"
   },
   "source": [
    "**Oczekiwane wartości:**\n",
    "\n",
    "a) \n",
    "[[  4.806   2.376   7.762   1.129]\n",
    " [ 12.164 -12.645  73.935   3.636]\n",
    " [ 27.79  -16.962  94.002   7.137]\n",
    " [ 18.702  -5.184  42.616   4.501]\n",
    " [ 64.38   49.86   56.21   14.45 ]] \n",
    "\n",
    "\n",
    "b) \n",
    "[[4.91780633e-02 4.32948093e-03 9.45248312e-01 1.24414389e-03]\n",
    " [1.49003187e-27 2.50486173e-38 1.00000000e+00 2.94803216e-31]\n",
    " [1.75587568e-29 6.44090821e-49 1.00000000e+00 1.88369172e-38]\n",
    " [4.11416552e-11 1.74069934e-21 1.00000000e+00 2.79811669e-17]\n",
    " [9.99716568e-01 4.94220792e-07 2.82937800e-04 2.06801368e-22]] \n",
    "\n",
    "c) \n",
    "[[ 9.69108631  0.35799187  0.59163688]\n",
    " [10.2         0.2         0.3       ]\n",
    " [10.2         0.2         0.3       ]\n",
    " [10.2         0.2         0.3       ]\n",
    " [ 1.20254471  3.39909302  5.59850122]]\n",
    " \n",
    " (albo to samo transponowane)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a9220arNHo1V"
   },
   "source": [
    "## Zadanie 2 (2 punkty): tokenizacja tekstu \n",
    "\n",
    "Korzystając z biblioteki transformers (https://huggingface.co/transformers/) wczytaj tokenizator BERTa (BERT to już wytrenowany (pretrenowany) model, oparty o ideę transformera (a w zasadzie o jego enkoder)). Ponieważ model jest gotowy i można go wykorzystać do generowania embeddingów tokenów, ważnym jest, aby tokenizacja była przeprowadzona identycznie do tego jak podczas trenowania BERTa.\n",
    "\n",
    "Wybierzmy pretrenowany tokenizator o nazwie `bert-base-uncased` i zobaczmy jaki będzie efekt tokenizacji na tekście zawartym w zmiennej `text_to_tokenize`.\n",
    "\n",
    "Zwróć uwagę na to, że niektóre rzadkie słowa zostały podzielone na subtokeny -- zgodnie z algorytmem WordPiece jaki omawialiśmy na przedostatnim spotkaniu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "uMLn-hE8L6Zh"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7eb86c7295d649fea9db97a8e68a24aa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "706a3bd87fdb487ba4bea594ea34bad1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0d65c6bf4c114da3b1a4b07d2e503b44"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', \"'\", 've', 'bought', 'a', 'new', 'gp', '##u', 'last', 'year', 'it', 'was', 'ge', '##force', 'rt', '##x', '306', '##0']\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "text_to_tokenize = \"I've bought a new GPU last year it was GeForce RTX 3060\"\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "tokens = tokenizer.tokenize(text_to_tokenize)\n",
    "\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RFwEeX2GOxEp"
   },
   "source": [
    "## Zadanie 3 (brak punktów):\n",
    "Poniżej znajduje się kod wykorzystujący przygotowane wcześniej zmienne `tokenizer` i `tokens` i które dla każdego tokenu z tokens generuje embedding. W odróżnieniu od GloVe, te embeddingi są świadome kontekstu w jakim właśnie występują. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XHlN4iH8P0Sv",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "import torch\n",
    "\n",
    "model = BertModel.from_pretrained('bert-base-uncased', return_dict=True)\n",
    "# nie chcemy trenować modelu, tylko go wykorzystać\n",
    "model.eval()\n",
    "\n",
    "# BERT wymaga specjalnych tokenów [CLS] na początku i [SEP] separującego pary zdań (BERT jest trenowany parami zdań)\n",
    "tokens_with_specials = ['CLS'] + tokens + ['SEP']\n",
    "# zamiana listy tokenów na listę identyfikatorów (liczb) ze słownika\n",
    "tokens_with_specials = tokenizer.convert_tokens_to_ids(\n",
    "  tokens_with_specials)\n",
    "# zamiana na tensor, opakowanie w batch\n",
    "tokens_tensor = torch.tensor([tokens_with_specials])\n",
    "\n",
    "# Wygeneruj maskę mówiącą o tym, które tokeny nalezą do zdania 1, a które do 2. W naszym zadaniu wszystkie tokeny nalezą do zdania 1\n",
    "segments = torch.tensor([[1] * len(tokens_with_specials)])\n",
    "\n",
    "with torch.no_grad():\n",
    "  # wygenerujmy embedding'i BERTem\n",
    "  outputs = model(tokens_tensor, segments)\n",
    "  # wez pierwszy batch danych i ostatnią warstwę\n",
    "  tokens_embeddings = outputs['last_hidden_state'][0]\n",
    "  # 20x768, mamy 20 (sub)tokenów, (18 właściwych + cls + sep) i każdy mapowany jest na wektor liczb o długości 768\n",
    "  print(tokens_embeddings.shape)\n",
    "  # wez embedding pierwszego sub-token'u z sekwencji (przeskakujemy CLS token)\n",
    "  print(tokens_embeddings[1])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Zadania10-2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}