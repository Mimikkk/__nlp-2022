{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D48rgmQSB0B6"
      },
      "source": [
        "# Laboratoria 9: BERT i atencja\n",
        "\n",
        "\n",
        "### Zadanie 1 (3 pkt), atencja dekodera względem (en)kodera\n",
        "\n",
        "Poniżej znajdują się dwie macierze, `encoder_states` oraz `decoder_states` reprezentujące stan warstwy ukrytej po przetworzeniu każdego slowa z enkodera i dekodera. Pojedynczy stan warstwy ukrytej zawiera embedding o dlugosci = 3. W enkoderze mamy 4 stany warstwy ukrytej RNNów, gdyż przetwarzamy sekwencję 4 tokenów.\n",
        "\n",
        "W dekoderze mamy 5 tokenów, które powinny być wygenerowane z sekwencji przetwarzanej (en)koderem.\n",
        "\n",
        "Zadanie polega na:\n",
        "a) Obliczniu podobieństwa wszystkich embeddingów z dekodera (queries) względem wszystkich embeddingów kolejnych stanów (en)kodera (keys) [pamiętajcie, że macierze potrafią w transponowanie. W `NumPy` macierz transponujemy za pomocą `macierz.T`]\n",
        "\n",
        "b) Na utworzonej macierzy podobieństwa należy wykonać softmax (zaimportowany z scipy). Uwaga:  pamiętajcie, żeby aplikować softmax w dobrym wymiarze. Wszystkie stany ukryte enkodera powinny zostac zasoftmaksowane względem zadanego stanu dekodera, nie odwrotnie. W scipy, funkcja softmax zawiera argument axis, który może pomóc.\n",
        "\n",
        "c) Należy wykorzystać macierz atencji z kroku b) i `encoder_states` do wygenerowania macierzy zawierającej wektory kontekstu dla każdego tokenu z dekodera.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQsum9iYATge"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.special import softmax\n",
        "\n",
        "# scipy.special.softmax(x, axis=None)\n",
        "\n",
        "encoder_states = np.array(\n",
        "    [[1.2, 3.4, 5.6],    # embedding z warstwy ukrytej enkodera w kroku 1,  np. dla slowa Ala\n",
        "    [-2.3, 0.2, 7.2],   # embedding z warstwy ukrytej enkodera w kroku 2,  np. dla slowa ma\n",
        "    [10.2, 0.2, 0.3],   # embedding z warstwy ukrytej enkodera w kroku 3,  np. dla slowa kota\n",
        "    [0.4, 0.7, 1.2]]    # embedding z warstwy ukrytej enkodera w kroku 4,  np. dla tokenu <EOS> (koniec sekwencji)\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "decoder_states = np.array(\n",
        "    [[0.74, 0.23, 0.56],  # embedding z warstwy ukrytej dekodera w kroku 1,  np. przed wygenerowaniem slowa Alice\n",
        "    [7.23, 0.12, 0.55],  # embedding z warstwy ukrytej dekodera w kroku 2,  np. przed wygenerowaniem slowa owns\n",
        "    [9.12, 4.23, 0.44],  # embedding z warstwy ukrytej dekodera w kroku 3,  np. przed wygenerowaniem slowa a\n",
        "    [4.1, 3.23, 0.5],    # embedding z warstwy ukrytej dekodera w kroku 4,  np. przed wygenerowaniem slowa cat\n",
        "    [5.2, 3.1, 8.5]]     # embedding z warstwy ukrytej dekodera w kroku 5,  np. przed wygenerowaniem slowa cat\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwhDwdaTnPku"
      },
      "source": [
        "**Oczekiwane wartości:**\n",
        "\n",
        "a) \n",
        "[[  4.806   2.376   7.762   1.129]\n",
        " [ 12.164 -12.645  73.935   3.636]\n",
        " [ 27.79  -16.962  94.002   7.137]\n",
        " [ 18.702  -5.184  42.616   4.501]\n",
        " [ 64.38   49.86   56.21   14.45 ]] \n",
        "\n",
        "\n",
        "b) \n",
        "[[4.91780633e-02 4.32948093e-03 9.45248312e-01 1.24414389e-03]\n",
        " [1.49003187e-27 2.50486173e-38 1.00000000e+00 2.94803216e-31]\n",
        " [1.75587568e-29 6.44090821e-49 1.00000000e+00 1.88369172e-38]\n",
        " [4.11416552e-11 1.74069934e-21 1.00000000e+00 2.79811669e-17]\n",
        " [9.99716568e-01 4.94220792e-07 2.82937800e-04 2.06801368e-22]] \n",
        "\n",
        "c) \n",
        "[[ 9.69108631  0.35799187  0.59163688]\n",
        " [10.2         0.2         0.3       ]\n",
        " [10.2         0.2         0.3       ]\n",
        " [10.2         0.2         0.3       ]\n",
        " [ 1.20254471  3.39909302  5.59850122]]\n",
        " \n",
        " (albo to samo transponowane)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9220arNHo1V"
      },
      "source": [
        "## Zadanie 2 (2 punkty): tokenizacja tekstu \n",
        "\n",
        "Korzystając z biblioteki transformers (https://huggingface.co/transformers/) wczytaj tokenizator BERTa (BERT to już wytrenowany (pretrenowany) model, oparty o ideę transformera (a w zasadzie o jego enkoder)). Ponieważ model jest gotowy i można go wykorzystać do generowania embeddingów tokenów, ważnym jest, aby tokenizacja była przeprowadzona identycznie do tego jak podczas trenowania BERTa.\n",
        "\n",
        "Wybierzmy pretrenowany tokenizator o nazwie `bert-base-uncased` i zobaczmy jaki będzie efekt tokenizacji na tekście zawartym w zmiennej `text_to_tokenize`.\n",
        "\n",
        "Zwróć uwagę na to, że niektóre rzadkie słowa zostały podzielone na subtokeny -- zgodnie z algorytmem WordPiece jaki omawialiśmy na przedostatnim spotkaniu.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxcU6_pYNgfP"
      },
      "outputs": [],
      "source": [
        "# Uruchom mnie proszę\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMLn-hE8L6Zh"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer\n",
        "text_to_tokenize = \"I've bought a new GPU last year it was GeForce RTX 3060\"\n",
        "tokenizer = None\n",
        "tokens = None\n",
        "\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOr1m9n6Mw3V"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFwEeX2GOxEp"
      },
      "source": [
        "## Zadanie 3 (brak punktów):\n",
        "Poniżej znajduje się kod wykorzystujący przygotowane wcześniej zmienne `tokenizer` i `tokens` i które dla każdego tokenu z tokens generuje embedding. W odróżnieniu od GloVe, te embeddingi są świadome kontekstu w jakim właśnie występują. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHlN4iH8P0Sv"
      },
      "outputs": [],
      "source": [
        "from transformers import BertModel\n",
        "import torch\n",
        "\n",
        "model = BertModel.from_pretrained('bert-base-uncased', return_dict=True)  \n",
        "model.eval()  # nie chcemy trenowac modelu, tylko go wykorzystac\n",
        "\n",
        "tokens_with_specials = ['CLS'] + tokens + ['SEP']  # BERT wymaga specjalnych tokenów [CLS] na poczatku i [SEP] separaującego pary zdań (BERT jest trenowany parami zdań)\n",
        "tokens_with_specials = tokenizer.convert_tokens_to_ids(tokens_with_specials)  # zamiana listy tokenow na listę identyfikatorów (liczb) ze slownika\n",
        "tokens_tensor = torch.tensor([tokens_with_specials])  # zamiana na tensor, opakowanie w batch\n",
        "\n",
        "segments = torch.tensor([[1] * len(tokens_with_specials)])  # wygeneruj maskę mówiącą o tym które tokeny nalezą do zdania 1, a ktore do 2. W naszym zadaniu wszystkie tokeny naleza do zdania 1\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(tokens_tensor, segments)  # wygenerujmy embeddingi BERTem\n",
        "    tokens_embeddings = outputs['last_hidden_state'][0]  # wez pierwszy batch danych i ostatnią warstwę\n",
        "    print(tokens_embeddings.shape)  # 20x768, mamy 20 (sub)tokenów, (18 wlasciwych + cls + sep) i kazdy mapowany jest na wektor liczb o dlugosci 768\n",
        "    print(tokens_embeddings[1])  # wez embedding pierwszego subtokenu z sekwencji (przeskakujemy CLS token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWi18mj6T_S5"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Zadania10-2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}