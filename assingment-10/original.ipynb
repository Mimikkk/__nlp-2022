{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "lab10.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Wykrywanie encji nazwanych z Flair\n",
    "\n",
    "To już ostatnie laboratoria zadaniowe, w związku z tym, jeśli znajdziecie chwilę wolnego czasu, wypełnijcie proszę ankietę: https://docs.google.com/forms/d/1rHPjpL70XdXRD-ILl3AHophPNUk0AhsFus1-mtkUPsI\n",
    "\n",
    "Pozwoli to mi poprawić laboratoria w przyszłości, z góry dziękuję :)\n",
    "\n",
    "# Flair\n",
    "\n",
    "Biblioteka Flair to bardzo popularne narzędzie do tagowania sekwencji. Zaintstalujmy ją"
   ],
   "metadata": {
    "id": "OcjJ-YZy5-Pl",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install flair"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# OPCJONALNE WSPARCIE DLA KART GRAFICZNYCH\n",
    "# W colabie możemy trenować z wykorzystaniem karty graficznej, dzięki temu trening działa dużo szybciej\n",
    "# Aby włączyć wsparcie dla karty graficznej musimy:\n",
    "# 1. w menu 'srodowisko wykonawcze' wybrać `zmien typ srodowiska wykonawczego` i tam `akcelerator sprzętowy` = GPU\n",
    "# 2. odkomentować linijki poniżej\n",
    "import flair, torch\n",
    "flair.device = torch.device('cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Ładowanie zbioru danych i słownika z etykietami.\n",
    "\n",
    "**Zadanie1: (1 punkt):** Stwórz słownik etykiet z wczytanego korpusu korzystając z funkcji `make_label_dictionary()`. W naszym zbiorze, etykiety do wykrycia występują w kolumnie `ner`, której identyfikator został zapisany w linijce 6. Tutorial: https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_6_CORPUS.md może okazać się pomocny.\n",
    "\n",
    "Efektem działania powinna być lista etykiet np:\n",
    "`Dictionary with 20 tags: <unk>, Variable, Class, Application, User_Interface_Element, Code_Block, Language, Function, Data_Structure, Library, Data_Type, File_Type, File_Name, Version, HTML_XML_Tag, Device, Operating_System, Website, User_Name, Algorithm`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-26 19:54:27,485 File train has 741 questions and 897 answers.\n",
      "2022-05-26 19:54:27,497 File test has 249 questions and 315 answers.\n",
      "2022-05-26 19:54:27,507 File dev has 247 questions and 289 answers.\n",
      "2022-05-26 19:54:27,508 Reading data from C:\\Users\\Hououin Kyouma\\.flair\\datasets\\ner_english_stackoverflow\n",
      "2022-05-26 19:54:27,508 Train: C:\\Users\\Hououin Kyouma\\.flair\\datasets\\ner_english_stackoverflow\\train.txt\n",
      "2022-05-26 19:54:27,508 Dev: C:\\Users\\Hououin Kyouma\\.flair\\datasets\\ner_english_stackoverflow\\dev.txt\n",
      "2022-05-26 19:54:27,509 Test: C:\\Users\\Hououin Kyouma\\.flair\\datasets\\ner_english_stackoverflow\\test.txt\n",
      "2022-05-26 19:54:31,497 Filtering empty sentences\n",
      "2022-05-26 19:54:31,512 Corpus: 926 train + 294 dev + 311 test sentences\n",
      "2022-05-26 19:54:31,514 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "926it [00:00, 70566.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-26 19:54:31,529 Dictionary created for label 'ner' with 20 values: Application (seen 138 times), Class (seen 125 times), User_Interface_Element (seen 117 times), Variable (seen 94 times), Language (seen 84 times), Library (seen 81 times), Code_Block (seen 79 times), Data_Structure (seen 71 times), Function (seen 67 times), Data_Type (seen 38 times), Version (seen 29 times), File_Type (seen 27 times), HTML_XML_Tag (seen 24 times), Device (seen 23 times), File_Name (seen 22 times), Operating_System (seen 12 times), Website (seen 11 times), User_Name (seen 6 times), Algorithm (seen 5 times)\n",
      "Etykiety do wykrycia Dictionary with 20 tags: <unk>, Application, Class, User_Interface_Element, Variable, Language, Library, Code_Block, Data_Structure, Function, Data_Type, Version, File_Type, HTML_XML_Tag, Device, File_Name, Operating_System, Website, User_Name, Algorithm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# zbiór otagowanych postów na Stacku\n",
    "from flair.datasets import NER_ENGLISH_STACKOVERFLOW\n",
    "\n",
    "# pobieramy korpus i zmniejszamy jego wielkość\n",
    "corpus = NER_ENGLISH_STACKOVERFLOW().downsample(0.1)\n",
    "# usuwamy puste zdania\n",
    "corpus.filter_empty_sentences()\n",
    "\n",
    "# identyfikator pod którym możemy dostać typy etykiet\n",
    "label_type = 'ner'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-26 19:54:47,224 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "926it [00:00, 68275.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-26 19:54:47,240 Dictionary created for label 'ner' with 20 values: Application (seen 138 times), Class (seen 125 times), User_Interface_Element (seen 117 times), Variable (seen 94 times), Language (seen 84 times), Library (seen 81 times), Code_Block (seen 79 times), Data_Structure (seen 71 times), Function (seen 67 times), Data_Type (seen 38 times), Version (seen 29 times), File_Type (seen 27 times), HTML_XML_Tag (seen 24 times), Device (seen 23 times), File_Name (seen 22 times), Operating_System (seen 12 times), Website (seen 11 times), User_Name (seen 6 times), Algorithm (seen 5 times)\n",
      "Etykiety do wykrycia Dictionary with 20 tags: <unk>, Application, Class, User_Interface_Element, Variable, Language, Library, Code_Block, Data_Structure, Function, Data_Type, Version, File_Type, HTML_XML_Tag, Device, File_Name, Operating_System, Website, User_Name, Algorithm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "label_dict = corpus.make_label_dictionary(label_type=label_type)\n",
    "print(f'Etykiety do wykrycia {label_dict}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Embeddingi\n",
    "\n",
    "W narzędziu Flair możemy bardzo prosto składać ze sobą różne embeddingi.\n",
    "\n",
    "**Zad2 (2 punkty):** Zapoznaj się z działaniem `StackedEmbeddings` opisanego w https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_3_WORD_EMBEDDING.md i zbuduj embeddingi zawierające reprezentacje pochodzące zarówno z Glove jak i Flairowe, oparte na `news-forward`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "from flair.embeddings import WordEmbeddings, StackedEmbeddings, FlairEmbeddings\n",
    "from flair.data import Sentence\n",
    "\n",
    "# TODO\n",
    "embeddings = StackedEmbeddings([\n",
    "  FlairEmbeddings('news-forward'),\n",
    "  WordEmbeddings('glove')\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Token' object has no attribute 'value'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[1;32mIn [38]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m sentence \u001B[38;5;241m=\u001B[39m Sentence(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfn foo() -> void \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m token \u001B[38;5;129;01min\u001B[39;00m sentence:\n\u001B[1;32m----> 4\u001B[0m   \u001B[38;5;28mprint\u001B[39m(\u001B[43mtoken\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalue\u001B[49m, token\u001B[38;5;241m.\u001B[39mscore)\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'Token' object has no attribute 'value'"
     ]
    }
   ],
   "source": [
    "sentence = Sentence('fn foo() -> void {}')\n",
    "\n",
    "for token in sentence:\n",
    "  print(token.value, token.score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tagger i trainer\n",
    "\n",
    "**Zadanie 3 (2 punkty)** Bazując na treściach opisanych w https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_7_TRAINING_A_MODEL.md przygotuj obiekt `SequenceTagger`, którego rozmiar wartswy ukrytej wyniesie 256. Do obiektu tego przekażemy stworzone wcześniej embeddingi, słownik `label_dict` i nazwę kolumny z etykietą ze zmiennej `label_type`. Ustawmy `use_crf` na True.\n",
    "\n",
    "Przygotuj obiekt `ModelTrainer`, który przyjmie zarówno nasz korpus jak i stworzony przed chwilą `SequenceTagger`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-26 20:03:31,262 SequenceTagger predicts: Dictionary with 77 tags: O, S-Application, B-Application, E-Application, I-Application, S-Class, B-Class, E-Class, I-Class, S-User_Interface_Element, B-User_Interface_Element, E-User_Interface_Element, I-User_Interface_Element, S-Variable, B-Variable, E-Variable, I-Variable, S-Language, B-Language, E-Language, I-Language, S-Library, B-Library, E-Library, I-Library, S-Code_Block, B-Code_Block, E-Code_Block, I-Code_Block, S-Data_Structure, B-Data_Structure, E-Data_Structure, I-Data_Structure, S-Function, B-Function, E-Function, I-Function, S-Data_Type, B-Data_Type, E-Data_Type, I-Data_Type, S-Version, B-Version, E-Version, I-Version, S-File_Type, B-File_Type, E-File_Type, I-File_Type, S-HTML_XML_Tag\n",
      "2022-05-26 20:03:31,304 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-26 20:03:31,305 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.05, inplace=False)\n",
      "        (encoder): Embedding(300, 100)\n",
      "        (rnn): LSTM(100, 2048)\n",
      "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (list_embedding_1): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=2148, out_features=2148, bias=True)\n",
      "  (rnn): LSTM(2148, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=79, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-05-26 20:03:31,306 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-26 20:03:31,306 Corpus: \"Corpus: 926 train + 294 dev + 311 test sentences\"\n",
      "2022-05-26 20:03:31,306 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-26 20:03:31,308 Parameters:\n",
      "2022-05-26 20:03:31,308  - learning_rate: \"0.100000\"\n",
      "2022-05-26 20:03:31,309  - mini_batch_size: \"32\"\n",
      "2022-05-26 20:03:31,309  - patience: \"3\"\n",
      "2022-05-26 20:03:31,309  - anneal_factor: \"0.5\"\n",
      "2022-05-26 20:03:31,310  - max_epochs: \"5\"\n",
      "2022-05-26 20:03:31,310  - shuffle: \"True\"\n",
      "2022-05-26 20:03:31,311  - train_with_dev: \"False\"\n",
      "2022-05-26 20:03:31,313  - batch_growth_annealing: \"False\"\n",
      "2022-05-26 20:03:31,313 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-26 20:03:31,314 Model training base path: \"resources\\taggers\\example-upos\"\n",
      "2022-05-26 20:03:31,315 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-26 20:03:31,315 Device: cpu\n",
      "2022-05-26 20:03:31,316 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-26 20:03:31,317 Embeddings storage mode: cpu\n",
      "2022-05-26 20:03:31,317 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-26 20:03:44,606 epoch 1 - iter 2/29 - loss 4.20838176 - samples/sec: 4.82 - lr: 0.100000\n",
      "2022-05-26 20:03:49,673 epoch 1 - iter 4/29 - loss 3.04663646 - samples/sec: 12.63 - lr: 0.100000\n",
      "2022-05-26 20:03:56,864 epoch 1 - iter 6/29 - loss 2.28994636 - samples/sec: 8.90 - lr: 0.100000\n",
      "2022-05-26 20:04:02,753 epoch 1 - iter 8/29 - loss 1.91309358 - samples/sec: 10.87 - lr: 0.100000\n",
      "2022-05-26 20:04:13,951 epoch 1 - iter 10/29 - loss 1.68598694 - samples/sec: 5.72 - lr: 0.100000\n",
      "2022-05-26 20:04:23,277 epoch 1 - iter 12/29 - loss 1.54318019 - samples/sec: 6.86 - lr: 0.100000\n",
      "2022-05-26 20:04:28,957 epoch 1 - iter 14/29 - loss 1.42604585 - samples/sec: 11.27 - lr: 0.100000\n",
      "2022-05-26 20:04:36,411 epoch 1 - iter 16/29 - loss 1.34337072 - samples/sec: 8.59 - lr: 0.100000\n",
      "2022-05-26 20:04:45,069 epoch 1 - iter 18/29 - loss 1.26732870 - samples/sec: 7.39 - lr: 0.100000\n",
      "2022-05-26 20:04:57,799 epoch 1 - iter 20/29 - loss 1.21261704 - samples/sec: 5.03 - lr: 0.100000\n",
      "2022-05-26 20:05:07,024 epoch 1 - iter 22/29 - loss 1.15205987 - samples/sec: 6.94 - lr: 0.100000\n",
      "2022-05-26 20:05:13,234 epoch 1 - iter 24/29 - loss 1.11524569 - samples/sec: 10.31 - lr: 0.100000\n",
      "2022-05-26 20:05:20,811 epoch 1 - iter 26/29 - loss 1.08367113 - samples/sec: 8.45 - lr: 0.100000\n",
      "2022-05-26 20:05:27,266 epoch 1 - iter 28/29 - loss 1.06731355 - samples/sec: 9.91 - lr: 0.100000\n",
      "2022-05-26 20:05:30,482 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-26 20:05:30,482 EPOCH 1 done: loss 1.0529 - lr 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:24<00:00,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-26 20:05:54,759 Evaluating as a multi-label problem: False\n",
      "2022-05-26 20:05:54,767 DEV : loss 0.5774096846580505 - f1-score (micro avg)  0.0\n",
      "2022-05-26 20:05:54,785 BAD EPOCHS (no improvement): 0\n",
      "2022-05-26 20:05:54,786 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-26 20:05:57,872 epoch 2 - iter 2/29 - loss 0.63576726 - samples/sec: 20.76 - lr: 0.100000\n",
      "2022-05-26 20:05:59,557 epoch 2 - iter 4/29 - loss 0.66468348 - samples/sec: 37.99 - lr: 0.100000\n",
      "2022-05-26 20:06:02,122 epoch 2 - iter 6/29 - loss 0.68594443 - samples/sec: 24.97 - lr: 0.100000\n",
      "2022-05-26 20:06:04,469 epoch 2 - iter 8/29 - loss 0.70621169 - samples/sec: 27.31 - lr: 0.100000\n",
      "2022-05-26 20:06:07,058 epoch 2 - iter 10/29 - loss 0.68488611 - samples/sec: 24.73 - lr: 0.100000\n",
      "2022-05-26 20:06:09,470 epoch 2 - iter 12/29 - loss 0.67300155 - samples/sec: 26.54 - lr: 0.100000\n",
      "2022-05-26 20:06:15,623 epoch 2 - iter 14/29 - loss 0.66140667 - samples/sec: 10.40 - lr: 0.100000\n",
      "2022-05-26 20:06:18,114 epoch 2 - iter 16/29 - loss 0.67685919 - samples/sec: 25.71 - lr: 0.100000\n",
      "2022-05-26 20:06:19,980 epoch 2 - iter 18/29 - loss 0.66057448 - samples/sec: 34.32 - lr: 0.100000\n",
      "2022-05-26 20:06:21,521 epoch 2 - iter 20/29 - loss 0.65636615 - samples/sec: 41.55 - lr: 0.100000\n",
      "2022-05-26 20:06:23,624 epoch 2 - iter 22/29 - loss 0.64099252 - samples/sec: 30.45 - lr: 0.100000\n",
      "2022-05-26 20:06:25,569 epoch 2 - iter 24/29 - loss 0.62275675 - samples/sec: 32.92 - lr: 0.100000\n",
      "2022-05-26 20:06:28,141 epoch 2 - iter 26/29 - loss 0.61561341 - samples/sec: 24.89 - lr: 0.100000\n",
      "2022-05-26 20:06:32,012 epoch 2 - iter 28/29 - loss 0.60703036 - samples/sec: 16.54 - lr: 0.100000\n",
      "2022-05-26 20:06:33,974 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-26 20:06:33,975 EPOCH 2 done: loss 0.6058 - lr 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-26 20:06:35,860 Evaluating as a multi-label problem: False\n",
      "2022-05-26 20:06:35,868 DEV : loss 0.5335744619369507 - f1-score (micro avg)  0.0\n",
      "2022-05-26 20:06:35,886 BAD EPOCHS (no improvement): 0\n",
      "2022-05-26 20:06:35,888 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-26 20:06:37,648 epoch 3 - iter 2/29 - loss 0.58825912 - samples/sec: 36.38 - lr: 0.100000\n",
      "2022-05-26 20:06:39,411 epoch 3 - iter 4/29 - loss 0.51276081 - samples/sec: 36.33 - lr: 0.100000\n",
      "2022-05-26 20:06:41,728 epoch 3 - iter 6/29 - loss 0.56522739 - samples/sec: 27.64 - lr: 0.100000\n",
      "2022-05-26 20:06:44,124 epoch 3 - iter 8/29 - loss 0.59308206 - samples/sec: 26.74 - lr: 0.100000\n",
      "2022-05-26 20:06:46,090 epoch 3 - iter 10/29 - loss 0.60301738 - samples/sec: 32.58 - lr: 0.100000\n",
      "2022-05-26 20:06:50,470 epoch 3 - iter 12/29 - loss 0.60185444 - samples/sec: 14.62 - lr: 0.100000\n",
      "2022-05-26 20:06:52,496 epoch 3 - iter 14/29 - loss 0.61446699 - samples/sec: 31.63 - lr: 0.100000\n",
      "2022-05-26 20:06:55,456 epoch 3 - iter 16/29 - loss 0.59170367 - samples/sec: 21.63 - lr: 0.100000\n",
      "2022-05-26 20:06:58,133 epoch 3 - iter 18/29 - loss 0.58467202 - samples/sec: 23.93 - lr: 0.100000\n",
      "2022-05-26 20:07:00,510 epoch 3 - iter 20/29 - loss 0.57637136 - samples/sec: 26.95 - lr: 0.100000\n",
      "2022-05-26 20:07:04,147 epoch 3 - iter 22/29 - loss 0.58151793 - samples/sec: 17.60 - lr: 0.100000\n",
      "2022-05-26 20:07:06,032 epoch 3 - iter 24/29 - loss 0.56606301 - samples/sec: 33.96 - lr: 0.100000\n",
      "2022-05-26 20:07:09,109 epoch 3 - iter 26/29 - loss 0.57049803 - samples/sec: 20.81 - lr: 0.100000\n",
      "2022-05-26 20:07:11,171 epoch 3 - iter 28/29 - loss 0.56062215 - samples/sec: 31.05 - lr: 0.100000\n",
      "2022-05-26 20:07:12,215 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-26 20:07:12,216 EPOCH 3 done: loss 0.5606 - lr 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-26 20:07:14,064 Evaluating as a multi-label problem: False\n",
      "2022-05-26 20:07:14,071 DEV : loss 0.5206838846206665 - f1-score (micro avg)  0.0\n",
      "2022-05-26 20:07:14,085 BAD EPOCHS (no improvement): 0\n",
      "2022-05-26 20:07:14,086 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-26 20:07:16,871 epoch 4 - iter 2/29 - loss 0.63002666 - samples/sec: 22.98 - lr: 0.100000\n",
      "2022-05-26 20:07:19,205 epoch 4 - iter 4/29 - loss 0.64011662 - samples/sec: 27.44 - lr: 0.100000\n",
      "2022-05-26 20:07:21,422 epoch 4 - iter 6/29 - loss 0.59524212 - samples/sec: 28.88 - lr: 0.100000\n",
      "2022-05-26 20:07:22,991 epoch 4 - iter 8/29 - loss 0.58330252 - samples/sec: 40.81 - lr: 0.100000\n",
      "2022-05-26 20:07:25,516 epoch 4 - iter 10/29 - loss 0.55273587 - samples/sec: 25.37 - lr: 0.100000\n",
      "2022-05-26 20:07:28,443 epoch 4 - iter 12/29 - loss 0.53068954 - samples/sec: 21.87 - lr: 0.100000\n",
      "2022-05-26 20:07:30,529 epoch 4 - iter 14/29 - loss 0.54583058 - samples/sec: 30.73 - lr: 0.100000\n",
      "2022-05-26 20:07:32,938 epoch 4 - iter 16/29 - loss 0.54259420 - samples/sec: 26.58 - lr: 0.100000\n",
      "2022-05-26 20:07:34,625 epoch 4 - iter 18/29 - loss 0.54861867 - samples/sec: 37.96 - lr: 0.100000\n",
      "2022-05-26 20:07:38,204 epoch 4 - iter 20/29 - loss 0.54790529 - samples/sec: 17.88 - lr: 0.100000\n",
      "2022-05-26 20:07:41,183 epoch 4 - iter 22/29 - loss 0.52924432 - samples/sec: 21.49 - lr: 0.100000\n",
      "2022-05-26 20:07:43,184 epoch 4 - iter 24/29 - loss 0.53056131 - samples/sec: 32.03 - lr: 0.100000\n",
      "2022-05-26 20:07:48,415 epoch 4 - iter 26/29 - loss 0.52888272 - samples/sec: 12.24 - lr: 0.100000\n",
      "2022-05-26 20:07:50,973 epoch 4 - iter 28/29 - loss 0.52336165 - samples/sec: 25.03 - lr: 0.100000\n",
      "2022-05-26 20:07:51,873 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-26 20:07:51,873 EPOCH 4 done: loss 0.5240 - lr 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-26 20:07:53,711 Evaluating as a multi-label problem: False\n",
      "2022-05-26 20:07:53,719 DEV : loss 0.48045143485069275 - f1-score (micro avg)  0.1409\n",
      "2022-05-26 20:07:53,732 BAD EPOCHS (no improvement): 0\n",
      "2022-05-26 20:07:53,735 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-26 20:07:54,367 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-26 20:07:56,137 epoch 5 - iter 2/29 - loss 0.48636664 - samples/sec: 36.19 - lr: 0.100000\n",
      "2022-05-26 20:07:59,003 epoch 5 - iter 4/29 - loss 0.52124258 - samples/sec: 22.34 - lr: 0.100000\n",
      "2022-05-26 20:08:01,285 epoch 5 - iter 6/29 - loss 0.52689316 - samples/sec: 28.06 - lr: 0.100000\n",
      "2022-05-26 20:08:02,853 epoch 5 - iter 8/29 - loss 0.51417840 - samples/sec: 40.83 - lr: 0.100000\n",
      "2022-05-26 20:08:08,036 epoch 5 - iter 10/29 - loss 0.52198651 - samples/sec: 12.35 - lr: 0.100000\n",
      "2022-05-26 20:08:10,495 epoch 5 - iter 12/29 - loss 0.50259419 - samples/sec: 26.04 - lr: 0.100000\n",
      "2022-05-26 20:08:12,256 epoch 5 - iter 14/29 - loss 0.49795783 - samples/sec: 36.37 - lr: 0.100000\n",
      "2022-05-26 20:08:14,222 epoch 5 - iter 16/29 - loss 0.49099817 - samples/sec: 32.59 - lr: 0.100000\n",
      "2022-05-26 20:08:17,105 epoch 5 - iter 18/29 - loss 0.49293644 - samples/sec: 22.21 - lr: 0.100000\n",
      "2022-05-26 20:08:18,864 epoch 5 - iter 20/29 - loss 0.50800626 - samples/sec: 36.39 - lr: 0.100000\n",
      "2022-05-26 20:08:21,184 epoch 5 - iter 22/29 - loss 0.50389542 - samples/sec: 27.59 - lr: 0.100000\n",
      "2022-05-26 20:08:23,696 epoch 5 - iter 24/29 - loss 0.50854167 - samples/sec: 25.50 - lr: 0.100000\n",
      "2022-05-26 20:08:26,749 epoch 5 - iter 26/29 - loss 0.51198178 - samples/sec: 20.97 - lr: 0.100000\n",
      "2022-05-26 20:08:30,382 epoch 5 - iter 28/29 - loss 0.50617536 - samples/sec: 17.63 - lr: 0.100000\n",
      "2022-05-26 20:08:31,141 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-26 20:08:31,142 EPOCH 5 done: loss 0.5052 - lr 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-26 20:08:33,023 Evaluating as a multi-label problem: False\n",
      "2022-05-26 20:08:33,031 DEV : loss 0.43200454115867615 - f1-score (micro avg)  0.1542\n",
      "2022-05-26 20:08:33,044 BAD EPOCHS (no improvement): 0\n",
      "2022-05-26 20:08:33,047 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-26 20:08:34,268 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-26 20:08:34,269 loading file resources\\taggers\\example-upos\\best-model.pt\n",
      "2022-05-26 20:08:34,725 SequenceTagger predicts: Dictionary with 79 tags: O, S-Application, B-Application, E-Application, I-Application, S-Class, B-Class, E-Class, I-Class, S-User_Interface_Element, B-User_Interface_Element, E-User_Interface_Element, I-User_Interface_Element, S-Variable, B-Variable, E-Variable, I-Variable, S-Language, B-Language, E-Language, I-Language, S-Library, B-Library, E-Library, I-Library, S-Code_Block, B-Code_Block, E-Code_Block, I-Code_Block, S-Data_Structure, B-Data_Structure, E-Data_Structure, I-Data_Structure, S-Function, B-Function, E-Function, I-Function, S-Data_Type, B-Data_Type, E-Data_Type, I-Data_Type, S-Version, B-Version, E-Version, I-Version, S-File_Type, B-File_Type, E-File_Type, I-File_Type, S-HTML_XML_Tag\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:31<00:00,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-26 20:09:06,766 Evaluating as a multi-label problem: False\n",
      "2022-05-26 20:09:06,774 0.1646\t0.069\t0.0972\t0.0602\n",
      "2022-05-26 20:09:06,774 \n",
      "Results:\n",
      "- F-score (micro) 0.0972\n",
      "- F-score (macro) 0.0348\n",
      "- Accuracy 0.0602\n",
      "\n",
      "By class:\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           Application     0.1148    0.1273    0.1207        55\n",
      "                 Class     0.2973    0.2245    0.2558        49\n",
      "              Language     0.1944    0.3182    0.2414        22\n",
      "               Library     0.0714    0.0312    0.0435        32\n",
      "              Variable     0.0000    0.0000    0.0000        40\n",
      "            Code_Block     0.0000    0.0000    0.0000        37\n",
      "User_Interface_Element     0.0000    0.0000    0.0000        32\n",
      "              Function     0.0000    0.0000    0.0000        23\n",
      "             File_Name     0.0000    0.0000    0.0000        22\n",
      "               Version     0.0000    0.0000    0.0000        16\n",
      "             File_Type     0.0000    0.0000    0.0000        11\n",
      "        Data_Structure     0.0000    0.0000    0.0000        12\n",
      "      Operating_System     0.0000    0.0000    0.0000        10\n",
      "               Website     0.0000    0.0000    0.0000         5\n",
      "                Device     0.0000    0.0000    0.0000         3\n",
      "          HTML_XML_Tag     0.0000    0.0000    0.0000         3\n",
      "             Algorithm     0.0000    0.0000    0.0000         2\n",
      "             Data_Type     0.0000    0.0000    0.0000         2\n",
      "             User_Name     0.0000    0.0000    0.0000         1\n",
      "\n",
      "             micro avg     0.1646    0.0690    0.0972       377\n",
      "             macro avg     0.0357    0.0369    0.0348       377\n",
      "          weighted avg     0.0728    0.0690    0.0686       377\n",
      "\n",
      "2022-05-26 20:09:06,776 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-26 20:09:06,779 loading file resources/taggers/example-upos/final-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-26 20:09:07,260 SequenceTagger predicts: Dictionary with 79 tags: O, S-Application, B-Application, E-Application, I-Application, S-Class, B-Class, E-Class, I-Class, S-User_Interface_Element, B-User_Interface_Element, E-User_Interface_Element, I-User_Interface_Element, S-Variable, B-Variable, E-Variable, I-Variable, S-Language, B-Language, E-Language, I-Language, S-Library, B-Library, E-Library, I-Library, S-Code_Block, B-Code_Block, E-Code_Block, I-Code_Block, S-Data_Structure, B-Data_Structure, E-Data_Structure, I-Data_Structure, S-Function, B-Function, E-Function, I-Function, S-Data_Type, B-Data_Type, E-Data_Type, I-Data_Type, S-Version, B-Version, E-Version, I-Version, S-File_Type, B-File_Type, E-File_Type, I-File_Type, S-HTML_XML_Tag\n"
     ]
    }
   ],
   "source": [
    "from flair.models import SequenceTagger\n",
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "\n",
    "# TODO\n",
    "tagger = SequenceTagger(hidden_size=256, embeddings=embeddings, tag_dictionary=label_dict, tag_type=label_type)\n",
    "\n",
    "# TODO\n",
    "trainer = ModelTrainer(tagger, corpus)\n",
    "\n",
    "#stworzony trainer możemy zacząć trenować!\n",
    "trainer.train('resources/taggers/example-upos', learning_rate=0.1, mini_batch_size=32, max_epochs=5)\n",
    "\n",
    "# a kiedy wytrenujemy, wczytujemy najlepszy model.\n",
    "model = SequenceTagger.load('resources/taggers/example-upos/final-model.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Predykcja z udziałem modelu\n",
    "\n",
    "Jeśli model został wytrenowany, poniżej znajdziemy fragment kodu, który może wykryć encje w zdaniach."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: \"fn foo () -> void {}\" → [\"fn\"/Library, \"foo\"/File_Type, \"()\"/Application]\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "\n",
    "# Jeśli nasz model się wyuczył, powinien wykryć Python jako język.\n",
    "# Uwaga, ponieważ pracujemy na niewielkim podzbiorze zbioru danych (downsample(0.1) próbkuje 10%),\n",
    "# otrzymywane wyniki mogą być kiepskiej jakości, najlepiej zwiększyść ilość danych\n",
    "# jeśli pracujemy w domu.\n",
    "# stwórz obiekt zdania\n",
    "sentence = Sentence('fn foo() -> void {}')\n",
    "# wykryj encje nazwane\n",
    "model.predict(sentence)\n",
    "# wyświetl zdanie i wykryte w nim encje\n",
    "print(sentence.to_tagged_string())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}